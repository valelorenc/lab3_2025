{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a96aec",
   "metadata": {},
   "source": [
    "# 1 - Consturcción de Dat Set Inicial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f20b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\01994\\AppData\\Local\\Temp\\ipykernel_26444\\1714545469.py:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv('sell-in.txt', sep='\\s+')\n",
      "C:\\Users\\01994\\AppData\\Local\\Temp\\ipykernel_26444\\1714545469.py:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_stocks = pd.read_csv('tb_stocks.txt', sep='\\s+')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Cargando y preparando datos...\n",
      "2. Generando features básicos...\n",
      "3. Generando features avanzados alternativos...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Carga y Preprocesamiento Inicial\n",
    "# ---------------------------------------------------\n",
    "print(\"1. Cargando y preparando datos...\")\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('sell-in.txt', sep='\\s+')\n",
    "#df_sell_in = pd.read_csv('sell-in.txt', sep='\\s+')\n",
    "df_stocks = pd.read_csv('tb_stocks.txt', sep='\\s+')\n",
    "df_productos = pd.read_csv('tb_productos.txt', sep='\\t')\n",
    "df_target_products = pd.read_csv('product_id_apredecir201912.txt', sep='\\t')\n",
    "\n",
    "\n",
    "# Convertir periodo a datetime y ordenar\n",
    "df['periodo'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "df = df.sort_values(['product_id', 'periodo'])\n",
    "\n",
    "# Agrupar por producto y periodo, sumando las tn\n",
    "df_agrupado = df.groupby(['product_id', 'periodo'])['tn'].sum().reset_index()\n",
    "\n",
    "# Opcional: Ordenar por producto y fecha\n",
    "df = df_agrupado.sort_values(['product_id', 'periodo'])\n",
    "\n",
    "# tn_0 es el tn actual\n",
    "#df.rename(columns={\"tn\": \"tn_0\"}, inplace=True)\n",
    "\n",
    "# Clase: tn del mes +2\n",
    "df[\"tn+2\"] = df.groupby(\"product_id\")[\"tn\"].shift(-2)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Feature Engineering Básico \n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Generar los lags tn_1 a tn_11 y clase = tn en periodo+2\n",
    "for i in range(1, 12):\n",
    "    df[f\"tn_{i}\"] = df.groupby(\"product_id\")[\"tn\"].shift(i)\n",
    "    \n",
    "    \n",
    "print(\"2. Generando features básicos...\")\n",
    "\n",
    "def generate_features(group):\n",
    "    group = group.sort_values('periodo')\n",
    "    target_col = 'tn'\n",
    "    \n",
    "    # 1. Estadísticas móviles (versión compatible)\n",
    "    windows = [3, 6, 12]\n",
    "    for w in windows:\n",
    "        group[f'{target_col}_avg_{w}'] = group[target_col].rolling(window=w, min_periods=1).mean()\n",
    "        group[f'{target_col}_std_{w}'] = group[target_col].rolling(window=w, min_periods=1).std()\n",
    "        group[f'{target_col}_min_{w}'] = group[target_col].rolling(window=w, min_periods=1).min()\n",
    "        group[f'{target_col}_max_{w}'] = group[target_col].rolling(window=w, min_periods=1).max()\n",
    "        group[f'{target_col}_median_{w}'] = group[target_col].rolling(window=w, min_periods=1).median()\n",
    "    \n",
    "    # 2. Diferencias y cambios porcentuales\n",
    "    lags = [1, 3, 12]\n",
    "    for lag in lags:\n",
    "        group[f'{target_col}_diff_{lag}'] = group[target_col].diff(periods=lag)\n",
    "        group[f'{target_col}_pct_{lag}'] = group[target_col].pct_change(periods=lag)\n",
    "    \n",
    "    # 3. Características de tendencia (versión segura)\n",
    "    def calculate_trend(x):\n",
    "        if len(x) < 2:\n",
    "            return np.nan\n",
    "        return np.polyfit(range(len(x)), x, 1)[0]\n",
    "    \n",
    "    group[f'{target_col}_trend_3'] = group[target_col].rolling(window=3).apply(calculate_trend, raw=True)\n",
    "    \n",
    "    # 4. Autocorrelación manual (versión compatible)\n",
    "    def calculate_autocorr(x, lag):\n",
    "        if len(x) < lag + 1:\n",
    "            return np.nan\n",
    "        return pd.Series(x).autocorr(lag=lag)\n",
    "    \n",
    "    for lag in [1, 3, 6]:\n",
    "        group[f'autocorr_{lag}'] = group[target_col].rolling(window=lag+10).apply(\n",
    "            lambda x: calculate_autocorr(x, lag), raw=True\n",
    "        )\n",
    "    \n",
    "    # 5. Características de clientes (versión corregida)\n",
    "    if 'customer_id' in group.columns:\n",
    "        # Alternativa a rolling().nunique() que funciona en Pandas 2.1.4\n",
    "        group['clientes_unicos_3'] = group['customer_id'].rolling(window=3, min_periods=1).apply(\n",
    "            lambda x: pd.Series(x).nunique(), raw=False\n",
    "        )\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Aplicar a cada producto (con manejo de errores)\n",
    "try:\n",
    "    df_features = df.groupby('product_id', group_keys=False).apply(generate_features)\n",
    "except Exception as e:\n",
    "    print(f\"Error durante el feature engineering: {str(e)}\")\n",
    "    # Versión alternativa más robusta\n",
    "    df_features = pd.concat([\n",
    "        generate_features(group) for _, group in df.groupby('product_id')\n",
    "    ])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Feature Engineering Avanzado Alternativo\n",
    "# ---------------------------------------------------\n",
    "print(\"3. Generando features avanzados alternativos...\")\n",
    "\n",
    "def advanced_features(group):\n",
    "    group = group.sort_values('periodo')\n",
    "    target = 'tn'\n",
    "    \n",
    "    # 1. Transformada de Fourier (versión segura)\n",
    "    def get_fft(x):\n",
    "        if len(x) < 3:\n",
    "            return [np.nan, np.nan]\n",
    "        try:\n",
    "            fft = np.fft.fft(x)\n",
    "            return [np.abs(fft[1]), np.angle(fft[1])]\n",
    "        except:\n",
    "            return [np.nan, np.nan]\n",
    "    \n",
    "    fft_results = group[target].rolling(window=12, min_periods=3).apply(\n",
    "        lambda x: get_fft(x)[0], raw=True\n",
    "    )\n",
    "    group['fft_abs'] = fft_results\n",
    "    \n",
    "    # 2. Entropía aproximada (versión simplificada)\n",
    "    group['entropy_6'] = group[target].rolling(window=6).apply(\n",
    "        lambda x: np.log(np.std(x) + 1e-6) if len(x) > 1 else np.nan, raw=True\n",
    "    )\n",
    "    \n",
    "    # 3. Cambios abruptos (versión robusta)\n",
    "    group['change_points'] = group[target].rolling(window=6).apply(\n",
    "        lambda x: np.sum(np.abs(np.diff(x)) > 2*np.std(x)) if len(x) > 1 else 0, raw=True\n",
    "    )\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Aplicar con manejo de errores\n",
    "try:\n",
    "    df_features = df_features.groupby('product_id', group_keys=False).apply(advanced_features)\n",
    "except Exception as e:\n",
    "    print(f\"Error en features avanzados: {str(e)}\")\n",
    "    df_features = pd.concat([\n",
    "        advanced_features(group) for _, group in df_features.groupby('product_id')\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d0dda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tn</th>\n",
       "      <th>tn+2</th>\n",
       "      <th>tn_1</th>\n",
       "      <th>tn_2</th>\n",
       "      <th>tn_3</th>\n",
       "      <th>tn_4</th>\n",
       "      <th>tn_5</th>\n",
       "      <th>tn_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tn_pct_3</th>\n",
       "      <th>tn_diff_12</th>\n",
       "      <th>tn_pct_12</th>\n",
       "      <th>tn_trend_3</th>\n",
       "      <th>autocorr_1</th>\n",
       "      <th>autocorr_3</th>\n",
       "      <th>autocorr_6</th>\n",
       "      <th>fft_abs</th>\n",
       "      <th>entropy_6</th>\n",
       "      <th>change_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.292745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>452.729232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>1520.06539</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.972550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458.049562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>1030.67391</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.421805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>599.106693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31238</th>\n",
       "      <td>21295</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.00699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31239</th>\n",
       "      <td>21296</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>0.00651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31240</th>\n",
       "      <td>21297</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.00579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31241</th>\n",
       "      <td>21298</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>0.00573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31242</th>\n",
       "      <td>21299</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>0.00546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31243 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id    periodo          tn        tn+2        tn_1        tn_2  \\\n",
       "0           20001 2017-01-01   934.77222  1303.35771         NaN         NaN   \n",
       "1           20001 2017-02-01   798.01620  1069.96130   934.77222         NaN   \n",
       "2           20001 2017-03-01  1303.35771  1502.20132   798.01620   934.77222   \n",
       "3           20001 2017-04-01  1069.96130  1520.06539  1303.35771   798.01620   \n",
       "4           20001 2017-05-01  1502.20132  1030.67391  1069.96130  1303.35771   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "31238       21295 2017-01-01     0.00699         NaN         NaN         NaN   \n",
       "31239       21296 2017-08-01     0.00651         NaN         NaN         NaN   \n",
       "31240       21297 2017-01-01     0.00579         NaN         NaN         NaN   \n",
       "31241       21298 2017-08-01     0.00573         NaN         NaN         NaN   \n",
       "31242       21299 2017-08-01     0.00546         NaN         NaN         NaN   \n",
       "\n",
       "            tn_3       tn_4  tn_5  tn_6  ...  tn_pct_3  tn_diff_12  tn_pct_12  \\\n",
       "0            NaN        NaN   NaN   NaN  ...       NaN         NaN        NaN   \n",
       "1            NaN        NaN   NaN   NaN  ...       NaN         NaN        NaN   \n",
       "2            NaN        NaN   NaN   NaN  ...       NaN         NaN        NaN   \n",
       "3      934.77222        NaN   NaN   NaN  ...  0.144622         NaN        NaN   \n",
       "4      798.01620  934.77222   NaN   NaN  ...  0.882420         NaN        NaN   \n",
       "...          ...        ...   ...   ...  ...       ...         ...        ...   \n",
       "31238        NaN        NaN   NaN   NaN  ...       NaN         NaN        NaN   \n",
       "31239        NaN        NaN   NaN   NaN  ...       NaN         NaN        NaN   \n",
       "31240        NaN        NaN   NaN   NaN  ...       NaN         NaN        NaN   \n",
       "31241        NaN        NaN   NaN   NaN  ...       NaN         NaN        NaN   \n",
       "31242        NaN        NaN   NaN   NaN  ...       NaN         NaN        NaN   \n",
       "\n",
       "       tn_trend_3  autocorr_1  autocorr_3  autocorr_6     fft_abs  entropy_6  \\\n",
       "0             NaN         NaN         NaN         NaN         NaN        NaN   \n",
       "1             NaN         NaN         NaN         NaN         NaN        NaN   \n",
       "2      184.292745         NaN         NaN         NaN  452.729232        NaN   \n",
       "3      135.972550         NaN         NaN         NaN  458.049562        NaN   \n",
       "4       99.421805         NaN         NaN         NaN  599.106693        NaN   \n",
       "...           ...         ...         ...         ...         ...        ...   \n",
       "31238         NaN         NaN         NaN         NaN         NaN        NaN   \n",
       "31239         NaN         NaN         NaN         NaN         NaN        NaN   \n",
       "31240         NaN         NaN         NaN         NaN         NaN        NaN   \n",
       "31241         NaN         NaN         NaN         NaN         NaN        NaN   \n",
       "31242         NaN         NaN         NaN         NaN         NaN        NaN   \n",
       "\n",
       "       change_points  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "...              ...  \n",
       "31238            NaN  \n",
       "31239            NaN  \n",
       "31240            NaN  \n",
       "31241            NaN  \n",
       "31242            NaN  \n",
       "\n",
       "[31243 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c7b287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Limpiando datos faltantes...\n",
      "Limpieza de valores faltantes completada exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 4. Manejo de Valores Faltantes (Versión Autónoma)\n",
    "# ---------------------------------------------------\n",
    "print(\"4. Limpiando datos faltantes...\")\n",
    "\n",
    "def clean_missing_values(df):\n",
    "    \"\"\"\n",
    "    Función autónoma para manejo de valores faltantes que:\n",
    "    1. Elimina columnas completamente vacías\n",
    "    2. Imputa valores según el tipo de feature\n",
    "    3. Elimina columnas con más del 30% de valores faltantes\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Eliminar columnas completamente vacías\n",
    "    empty_cols = [col for col in df.columns if df[col].isna().all()]\n",
    "    if empty_cols:\n",
    "        print(f\"Eliminando columnas vacías: {empty_cols}\")\n",
    "        df = df.drop(columns=empty_cols)\n",
    "    \n",
    "    # 2. Estrategias de imputación por tipo de feature\n",
    "    for col in df.columns:\n",
    "        if col == 'product_id':\n",
    "            continue  # No aplicar a la columna de identificación\n",
    "            \n",
    "        # Para cada grupo de producto\n",
    "        for product_id, group in df.groupby('product_id'):\n",
    "            mask = df['product_id'] == product_id\n",
    "            col_data = df.loc[mask, col]\n",
    "            \n",
    "            # a) Features estadísticos (promedios, std, etc.)\n",
    "            if any(x in col for x in ['_avg_', '_std_', '_min_', '_max_', '_median_']):\n",
    "                # Imputación con media expansiva\n",
    "                expanding_mean = col_data.expanding().mean()\n",
    "                df.loc[mask, col] = col_data.fillna(expanding_mean)\n",
    "            \n",
    "            # b) Features avanzados (tendencias, autocorrelación)\n",
    "            elif any(x in col for x in ['_trend_', 'autocorr_', 'fft_', 'entropy_']):\n",
    "                # Imputación con mediana del grupo\n",
    "                median_val = col_data.median()\n",
    "                df.loc[mask, col] = col_data.fillna(median_val)\n",
    "            \n",
    "            # c) Otros features\n",
    "            else:\n",
    "                # Forward fill + relleno con cero\n",
    "                filled = col_data.fillna(method='ffill').fillna(0)\n",
    "                df.loc[mask, col] = filled\n",
    "    \n",
    "    # 3. Eliminar columnas con muchos valores faltantes\n",
    "    threshold = int(0.7 * len(df))  # 70% de los datos como umbral\n",
    "    cols_to_drop = [col for col in df.columns if df[col].isna().sum() > (len(df) - threshold)]\n",
    "    \n",
    "    if cols_to_drop:\n",
    "        print(f\"Eliminando columnas con >30% NAs: {cols_to_drop}\")\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar la función\n",
    "try:\n",
    "    df_features = clean_missing_values(df_features)\n",
    "    print(\"Limpieza de valores faltantes completada exitosamente!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la limpieza: {str(e)}\")\n",
    "    # Opción de respaldo básica\n",
    "    df_features = df_features.fillna(0).dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b8aca44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tn</th>\n",
       "      <th>tn+2</th>\n",
       "      <th>tn_1</th>\n",
       "      <th>tn_2</th>\n",
       "      <th>tn_3</th>\n",
       "      <th>tn_4</th>\n",
       "      <th>tn_5</th>\n",
       "      <th>tn_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tn_pct_3</th>\n",
       "      <th>tn_diff_12</th>\n",
       "      <th>tn_pct_12</th>\n",
       "      <th>tn_trend_3</th>\n",
       "      <th>autocorr_1</th>\n",
       "      <th>autocorr_3</th>\n",
       "      <th>autocorr_6</th>\n",
       "      <th>fft_abs</th>\n",
       "      <th>entropy_6</th>\n",
       "      <th>change_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.633350</td>\n",
       "      <td>-0.070356</td>\n",
       "      <td>-0.342902</td>\n",
       "      <td>-0.086148</td>\n",
       "      <td>841.961582</td>\n",
       "      <td>5.385568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.633350</td>\n",
       "      <td>-0.070356</td>\n",
       "      <td>-0.342902</td>\n",
       "      <td>-0.086148</td>\n",
       "      <td>841.961582</td>\n",
       "      <td>5.385568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.292745</td>\n",
       "      <td>-0.070356</td>\n",
       "      <td>-0.342902</td>\n",
       "      <td>-0.086148</td>\n",
       "      <td>452.729232</td>\n",
       "      <td>5.385568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>1520.06539</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.972550</td>\n",
       "      <td>-0.070356</td>\n",
       "      <td>-0.342902</td>\n",
       "      <td>-0.086148</td>\n",
       "      <td>458.049562</td>\n",
       "      <td>5.385568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>1030.67391</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.421805</td>\n",
       "      <td>-0.070356</td>\n",
       "      <td>-0.342902</td>\n",
       "      <td>-0.086148</td>\n",
       "      <td>599.106693</td>\n",
       "      <td>5.385568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id    periodo          tn        tn+2        tn_1        tn_2  \\\n",
       "0       20001 2017-01-01   934.77222  1303.35771     0.00000     0.00000   \n",
       "1       20001 2017-02-01   798.01620  1069.96130   934.77222     0.00000   \n",
       "2       20001 2017-03-01  1303.35771  1502.20132   798.01620   934.77222   \n",
       "3       20001 2017-04-01  1069.96130  1520.06539  1303.35771   798.01620   \n",
       "4       20001 2017-05-01  1502.20132  1030.67391  1069.96130  1303.35771   \n",
       "\n",
       "        tn_3       tn_4  tn_5  tn_6  ...  tn_pct_3  tn_diff_12  tn_pct_12  \\\n",
       "0    0.00000    0.00000   0.0   0.0  ...  0.000000         0.0        0.0   \n",
       "1    0.00000    0.00000   0.0   0.0  ...  0.000000         0.0        0.0   \n",
       "2    0.00000    0.00000   0.0   0.0  ...  0.000000         0.0        0.0   \n",
       "3  934.77222    0.00000   0.0   0.0  ...  0.144622         0.0        0.0   \n",
       "4  798.01620  934.77222   0.0   0.0  ...  0.882420         0.0        0.0   \n",
       "\n",
       "   tn_trend_3  autocorr_1  autocorr_3  autocorr_6     fft_abs  entropy_6  \\\n",
       "0   77.633350   -0.070356   -0.342902   -0.086148  841.961582   5.385568   \n",
       "1   77.633350   -0.070356   -0.342902   -0.086148  841.961582   5.385568   \n",
       "2  184.292745   -0.070356   -0.342902   -0.086148  452.729232   5.385568   \n",
       "3  135.972550   -0.070356   -0.342902   -0.086148  458.049562   5.385568   \n",
       "4   99.421805   -0.070356   -0.342902   -0.086148  599.106693   5.385568   \n",
       "\n",
       "   change_points  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "382c1fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en sell_in_features_final.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 5. Exportar Resultados\n",
    "# ---------------------------------------------------\n",
    "def safe_export_to_csv(df, filename):\n",
    "    \"\"\"Exporta un DataFrame a CSV usando Python puro\"\"\"\n",
    "    try:\n",
    "        # Obtener columnas\n",
    "        columns = df.columns.tolist()\n",
    "        \n",
    "        # Abrir archivo en modo escritura\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            # Escribir encabezados\n",
    "            f.write(','.join(columns) + '\\n')\n",
    "            \n",
    "            # Escribir filas\n",
    "            for _, row in df.iterrows():\n",
    "                line = ','.join([str(row[col]) for col in columns]) + '\\n'\n",
    "                f.write(line)\n",
    "                \n",
    "        print(f\"Archivo guardado exitosamente en {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error al exportar: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Uso:\n",
    "safe_export_to_csv(df_features, 'sell_in_features_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
